from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from sklearn import svm
from sklearn.metrics import multilabel_confusion_matrix
import numpy as np
import src.Malware_Types as mt
from scipy.stats import ttest_ind
from sklearn.manifold import TSNE


def run_model(p,train_kernels, test_kernels,malware_train,malware_test,suffix = None):
    df = mt.getMalwareData()
    y_train = [0] * train_kernels['a_at'].shape[0]
    y_test = [0] * test_kernels['a_at'].shape[0]
    
    labels = {}
    for family,apps in malware_train.items():
        mal_type = (mt.condensedFaimlyData(df,family)['Malware_Type'].iloc[0])
        if 'Trojan' in mal_type:
            mal_type = 'Trojan'
        if mal_type not in labels:
            labels[mal_type] = len(labels) + 1
        
        i = labels[mal_type]
        for app_id in apps:
            y_train[app_id] = i
            
    f=open(p+'/Matrix_data/training_labels.csv','w')
    for ele in y_train:
        f.write(str(ele)+'\n')

    
            
    for family,apps in malware_test.items():
        mal_type = (mt.condensedFaimlyData(df,family)['Malware_Type'].iloc[0])
        if 'Trojan' in mal_type:
            mal_type = 'Trojan'

        i = labels[mal_type]
        for app_id in apps:
            y_test[app_id] = i
    f=open(p+'/Matrix_data/testing_labels.csv','w')
    for ele in y_test:
        f.write(str(ele)+'\n')
    clf = svm.LinearSVC(C=0.1, multi_class = 'ovr', dual = False)
    target_names = ['Benign'] + list(labels.keys())
    f = open(p + '/report_' + suffix + '.txt','w') 
    f1 = open(p + '/tsne_' + suffix + '.txt','w') 
    f2 = open(p + '/coef_' + suffix + '.txt','w') 
    all_preds = []
    for k,x in train_kernels.items():
        clf.fit(x, y_train)
        X_test = test_kernels[k]
        preds = clf.predict(X_test)
        all_preds.append(preds)
        X_embedded = TSNE(n_components=2).fit_transform(x.todense())
        
        
        report = classification_report(y_test,preds, target_names=target_names)
        report_2 = multilabel_confusion_matrix(y_test, preds)
        
        f.write(k)
        f1.write(k)
        f2.write(k)
        
        f.write('\n')
        f1.write('\n')
        f2.write('\n')
        
        f.write(report)
        f.write('\n') 
        for i,m in enumerate(report_2):
            f.write(target_names[i])
            f.write('\n')
            np.savetxt(f, m, delimiter=",", fmt = '%d')
        f.write('\n')
        
        f1.write('TSNE')
        f1.write('\n')
        np.savetxt(f1, X_embedded, delimiter=",")
        f1.write('\n')
        f2.write('coefs')
        f2.write('\n')
        np.savetxt(f2, clf.coef_, delimiter=",")
        f2.write('\n')
        f2.write('intercept')
        f2.write('\n')
        np.savetxt(f2, clf.intercept_, delimiter=",")

    
    f1.close()
    f2.close()
    preds = []
    f1 = open(p+'/preds_'+suffix+'.csv','w')
    for i in zip(*all_preds):
        preds.append(max(set(i), key=i.count))
        f1.write(str(preds[-1]))
        f1.write('\n')
    f.write('Ensemble - Max Voting')
    f.write('\n')
    report = classification_report(y_test,preds, target_names=target_names)
    report_2 = multilabel_confusion_matrix(y_test, preds)
    
    f.write(report)
    f.write('\n') 
    for i,m in enumerate(report_2):
        f.write(target_names[i])
        f.write('\n')
        np.savetxt(f, m, delimiter=",", fmt = '%d')
    f.write('\n')
        
    f.close()
    return preds
    
def run_ttest(p1,p2):
    print(ttest_ind(p1,p2))

    

                      

    