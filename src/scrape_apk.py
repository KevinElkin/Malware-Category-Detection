import requests
from bs4 import BeautifulSoup
import re
from collections import defaultdict
import gzip
import os
from random import sample 
import subprocess
from pathlib import Path
import io

base_url = 'https://apkpure.com'

def get_xml_zipped():
    """
    Method to get the links from the sitemap 

    Returns - list with all xml links
    """
    # ping request to sitemap.xml of APKPure
    xml_url = base_url + '/sitemap.xml'
    r = requests.get(xml_url)
    soup = BeautifulSoup(r.text, 'lxml')
    # extract just tags containing the .gz files 
    xml_links_tag = soup.find_all('loc')
    # adding each .gz file to a dictionary by category
    xml_links = defaultdict(list)
    for xml_link in xml_links_tag:
        xml_link = xml_link.text
        cat = xml_link.split('/')[-1]
        if '-' in cat:
            cat = cat.split('-')[0]
        else:
            cat = cat.split('.xml')[0]
        xml_links[cat].append(xml_link)
        
    return xml_links

def unzip_xml(sampled_xml, outpath):
    """
    Unzip .gz files and store the xml files in outpath/xml_files/cat_name

    
    Return: dictionary where 
        key = category 
        value = list of xml files 
    """
    #create xml files folder if it does not exist
    if not os.path.exists(outpath + '/xml_files'):
        os.mkdir(outpath + '/xml_files')

    xml_file_paths = defaultdict(list)
    #looping through xml files 
    for sample_xml in sampled_xml:
        #unzipping xml files 
        r = requests.get(sample_xml)
        compressed_gz = io.BytesIO(r.content)
        decompressed_gz = gzip.GzipFile(fileobj=compressed_gz)
        #getting file name 
        xml_name = sample_xml.split('/')[-1].replace('.gz', '')
        #getting category of app
        category = xml_name.split('-')[0]
        #create category folders if they dont exist
        if not os.path.exists(outpath + '/xml_files/' + category):
            os.mkdir(outpath + '/xml_files/' + category)
        #saving content of unzipped xml files 
        xml_out_path = outpath + '/xml_files/' + category + '/' + xml_name
        xml_file_paths[category].append(xml_out_path)
        with open(xml_out_path, 'wb') as outfile:
            outfile.write(decompressed_gz.read())
    return xml_file_paths

def get_sampled_app_links(xml_file_paths, n):
    """
    Sample n random files from all the xml files 

    Params:
        1.xml_file_paths - dictionary where 
            key = category 
            value = list of xml files 
        2.n - number of xml files to sample

    Return: dictionary where 
            key = category 
            value = list of apps in xml file
    """
    app_links = defaultdict(list)
    #looping through xml file paths for each category 
    for category, xml_paths in xml_file_paths.items():
        for xml_path in xml_paths:
            #read xml files and extract the links of apps
            with open(xml_path, "r") as f:
                contents = f.read()
                soup = BeautifulSoup(contents, 'lxml')
                app_link_loctag = soup.find_all('loc')
                for app_link_lt in app_link_loctag:
                    app_links[category].append(app_link_lt.text)
    #sample n app links from the entire sample space
    sampled_apps = defaultdict(list)
    for k,v in app_links.items():
        for l in (sample(v,n)):
            sampled_apps[k].append(l)
    return sampled_apps

def scrape_apps(sampled_apps,outpath):
    """
    Download apk file of the apps passed in

    Param - sampled_apps - dictionary where
            key = category 
            value = list of apps in xml file
    """
    #create APK folder
    if not os.path.exists(outpath + '/APK'):
        os.mkdir(outpath + '/APK' )

    

    #loop through app links for each category 
    for category, sampled_app_links in sampled_apps.items():
        #create category folders if they dont exist
        if not os.path.exists(outpath + '/APK/' + category):
            os.mkdir(outpath + '/APK/' + category)
        for sampled_app_link in sampled_app_links:
            #extract app name from url
            url_split = sampled_app_link.split('/')
            if 'group' == url_split[3]:
                app_name = url_split[4]
            else:
                app_name = url_split[3]
            #download link scraped on one of the two ways depending on the category
            r = requests.get(sampled_app_link)
            soup = BeautifulSoup(r.text, 'html.parser')
            download_link = soup.find('div', class_ = 'ny-down')
            if download_link != None:
                download_url = base_url + (download_link.find('a', class_ = 'da')['href'])
            else:
                download_url = base_url + (soup.find('div', class_ = 'down').find('a')['href'])
            
            try:
                #download APK file of the app 
                r = requests.get(download_url)
                soup = BeautifulSoup(r.text, 'html.parser')

                download_file = soup.find_all('a', class_ = "ga")[0]['href']
                r = requests.get(download_file, stream = True)
                data = r.content
                with open(outpath + '/APK/' + category + '/' + app_name +'.apk', 'wb') as fh:
                    fh.write(data)
                fh.close()
                with open(outpath + '/log.txt', 'a') as logger:
                    logger.write(app_name + ' downloaded\n')
                logger.close()

            except:
                #Error when link cant download
                with open(outpath + '/log.txt', 'a') as logger:
                    logger.write(app_name + ' failed to downloaded\n')
                logger.close()
                return False

def unzip_apk(outpath):
    """
    method to run apktool on all apps
    """
    #loop through all files with the apk extension and unzip contents
    pathlist = Path(outpath + '/APK').glob('**/*.apk')
    for i,path in enumerate(pathlist):
        path_in_str = str(path)
        # extract app name 
        app_name = path_in_str.split('/')[-1]
        # extract directory of file and cd into it
        directory = '/'.join(path_in_str.split('/')[:-1])
        os.chdir(directory)
        #run apktool to unzip apk file 
        test = subprocess.Popen(["/usr/local/bin/apktool","d", "force", app_name ], stdout=subprocess.PIPE)
        output = test.communicate()[0]
        #delete apk file
        os.remove(app_name)
        #cd back to home directory
        os.chdir('./../../../')


def run_scraper(categories, num_apps,outpath):
    xml_links = get_xml_zipped()
    for cats in categories:
        i = 0
        while i < num_apps:
            sampled_xml = sample(xml_links[cats], 1)
            # sample app links
            xml_file_paths = unzip_xml(sampled_xml,outpath)
            sampled_app_links = get_sampled_app_links(xml_file_paths, 1)
            #unzip apk files 
            success = scrape_apps(sampled_app_links,outpath)
            if success != False:
                i += 1
            unzip_apk(outpath)